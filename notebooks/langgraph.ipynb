{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set environment variables for API integrations\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"your-langsmith-api-key\"\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"  # Enables LangSmith tracing\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"intelligent-rag-system\"  # Project name for organizing LangSmith traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith tracing is enabled: True\n"
     ]
    }
   ],
   "source": [
    "from langsmith import utils\n",
    "\n",
    "# Check and print whether LangSmith tracing is currently enabled\n",
    "print(f\"LangSmith tracing is enabled: {utils.tracing_is_enabled()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv # Import function to load environment variables\n",
    "from langchain_openai import ChatOpenAI # Import the OpenAI chat model\n",
    "\n",
    "# Load environment variables from the .env file. The `override=True` argument\n",
    "# ensures that variables from the .env file will overwrite existing environment variables.\n",
    "load_dotenv(dotenv_path=\".env\", override=True)\n",
    "\n",
    "# Initialize the ChatOpenAI model. We're using a specific model from Llama 3.3 series.\n",
    "# This `model` object will be used throughout the notebook for all LLM interactions.\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import requests\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.pool import StaticPool\n",
    "\n",
    "def get_engine_for_chinook_db():\n",
    "    \"\"\"\n",
    "    Pull SQL file, populate in-memory database, and create engine.\n",
    "    \n",
    "    Downloads the Chinook database SQL script from GitHub and creates an in-memory \n",
    "    SQLite database populated with the sample data.\n",
    "    \n",
    "    Returns:\n",
    "        sqlalchemy.engine.Engine: SQLAlchemy engine connected to the in-memory database\n",
    "    \"\"\"\n",
    "    # Download the Chinook database SQL script from the official repository\n",
    "    url = \"https://raw.githubusercontent.com/lerocha/chinook-database/master/ChinookDatabase/DataSources/Chinook_Sqlite.sql\"\n",
    "    response = requests.get(url)\n",
    "    sql_script = response.text\n",
    "\n",
    "    # Create an in-memory SQLite database connection\n",
    "    # check_same_thread=False allows the connection to be used across threads\n",
    "    connection = sqlite3.connect(\":memory:\", check_same_thread=False)\n",
    "    \n",
    "    # Execute the SQL script to populate the database with sample data\n",
    "    connection.executescript(sql_script)\n",
    "    \n",
    "    # Create and return a SQLAlchemy engine that uses the populated connection\n",
    "    return create_engine(\n",
    "        \"sqlite://\",  # SQLite URL scheme\n",
    "        creator=lambda: connection,  # Function that returns the database connection\n",
    "        poolclass=StaticPool,  # Use StaticPool to maintain single connection\n",
    "        connect_args={\"check_same_thread\": False},  # Allow cross-thread usage\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the database engine with the Chinook sample data\n",
    "engine = get_engine_for_chinook_db()\n",
    "\n",
    "# Create a LangChain SQLDatabase wrapper around the engine\n",
    "# This provides convenient methods for database operations and query execution\n",
    "db = SQLDatabase(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "# Initialize long-term memory store for persistent data between conversations\n",
    "in_memory_store = InMemoryStore()\n",
    "\n",
    "# Initialize checkpointer for short-term memory within a single thread/conversation\n",
    "checkpointer = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from langgraph.managed.is_last_step import RemainingSteps\n",
    "\n",
    "class State(TypedDict):\n",
    "    \"\"\"\n",
    "    State schema for the multi-agent customer support workflow.\n",
    "    \n",
    "    This defines the shared data structure that flows between nodes in the graph,\n",
    "    representing the current snapshot of the conversation and agent state.\n",
    "    \"\"\"\n",
    "    # Customer identifier retrieved from account verification\n",
    "    customer_id: str\n",
    "    \n",
    "    # Conversation history with automatic message aggregation\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    \n",
    "    # User preferences and context loaded from long-term memory store\n",
    "    loaded_memory: str\n",
    "    \n",
    "    # Counter to prevent infinite recursion in agent workflow\n",
    "    remaining_steps: RemainingSteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "import ast\n",
    "\n",
    "@tool\n",
    "def get_albums_by_artist(artist: str):\n",
    "    \"\"\"\n",
    "    Get albums by an artist from the music database.\n",
    "    \n",
    "    Args:\n",
    "        artist (str): The name of the artist to search for albums.\n",
    "    \n",
    "    Returns:\n",
    "        str: Database query results containing album titles and artist names.\n",
    "    \"\"\"\n",
    "    return db.run(\n",
    "        f\"\"\"\n",
    "        SELECT Album.Title, Artist.Name \n",
    "        FROM Album \n",
    "        JOIN Artist ON Album.ArtistId = Artist.ArtistId \n",
    "        WHERE Artist.Name LIKE '%{artist}%';\n",
    "        \"\"\",\n",
    "        include_columns=True\n",
    "    )\n",
    "\n",
    "@tool\n",
    "def get_tracks_by_artist(artist: str):\n",
    "    \"\"\"\n",
    "    Get songs/tracks by an artist (or similar artists) from the music database.\n",
    "    \n",
    "    Args:\n",
    "        artist (str): The name of the artist to search for tracks.\n",
    "    \n",
    "    Returns:\n",
    "        str: Database query results containing song names and artist names.\n",
    "    \"\"\"\n",
    "    return db.run(\n",
    "        f\"\"\"\n",
    "        SELECT Track.Name as SongName, Artist.Name as ArtistName \n",
    "        FROM Album \n",
    "        LEFT JOIN Artist ON Album.ArtistId = Artist.ArtistId \n",
    "        LEFT JOIN Track ON Track.AlbumId = Album.AlbumId \n",
    "        WHERE Artist.Name LIKE '%{artist}%';\n",
    "        \"\"\",\n",
    "        include_columns=True\n",
    "    )\n",
    "\n",
    "@tool\n",
    "def get_songs_by_genre(genre: str):\n",
    "    \"\"\"\n",
    "    Fetch songs from the database that match a specific genre.\n",
    "    \n",
    "    This function first looks up the genre ID(s) for the given genre name,\n",
    "    then retrieves songs that belong to those genre(s), limiting results\n",
    "    to 8 songs grouped by artist.\n",
    "    \n",
    "    Args:\n",
    "        genre (str): The genre of the songs to fetch.\n",
    "    \n",
    "    Returns:\n",
    "        list[dict] or str: A list of songs with artist information that match \n",
    "                          the specified genre, or an error message if no songs found.\n",
    "    \"\"\"\n",
    "    # First, get the genre ID(s) for the specified genre\n",
    "    genre_id_query = f\"SELECT GenreId FROM Genre WHERE Name LIKE '%{genre}%'\"\n",
    "    genre_ids = db.run(genre_id_query)\n",
    "    \n",
    "    # Check if any genres were found\n",
    "    if not genre_ids:\n",
    "        return f\"No songs found for the genre: {genre}\"\n",
    "    \n",
    "    # Parse the genre IDs and format them for the SQL query\n",
    "    genre_ids = ast.literal_eval(genre_ids)\n",
    "    genre_id_list = \", \".join(str(gid[0]) for gid in genre_ids)\n",
    "\n",
    "    # Query for songs in the specified genre(s)\n",
    "    songs_query = f\"\"\"\n",
    "        SELECT Track.Name as SongName, Artist.Name as ArtistName\n",
    "        FROM Track\n",
    "        LEFT JOIN Album ON Track.AlbumId = Album.AlbumId\n",
    "        LEFT JOIN Artist ON Album.ArtistId = Artist.ArtistId\n",
    "        WHERE Track.GenreId IN ({genre_id_list})\n",
    "        GROUP BY Artist.Name\n",
    "        LIMIT 8;\n",
    "    \"\"\"\n",
    "    songs = db.run(songs_query, include_columns=True)\n",
    "    \n",
    "    # Check if any songs were found\n",
    "    if not songs:\n",
    "        return f\"No songs found for the genre: {genre}\"\n",
    "    \n",
    "    # Format the results into a structured list of dictionaries\n",
    "    formatted_songs = ast.literal_eval(songs)\n",
    "    return [\n",
    "        {\"Song\": song[\"SongName\"], \"Artist\": song[\"ArtistName\"]}\n",
    "        for song in formatted_songs\n",
    "    ]\n",
    "\n",
    "@tool\n",
    "def check_for_songs(song_title):\n",
    "    \"\"\"\n",
    "    Check if a song exists in the database by its name.\n",
    "    \n",
    "    Args:\n",
    "        song_title (str): The title of the song to search for.\n",
    "    \n",
    "    Returns:\n",
    "        str: Database query results containing all track information \n",
    "             for songs matching the given title.\n",
    "    \"\"\"\n",
    "    return db.run(\n",
    "        f\"\"\"\n",
    "        SELECT * FROM Track WHERE Name LIKE '%{song_title}%';\n",
    "        \"\"\",\n",
    "        include_columns=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all music-related tools for the agent\n",
    "music_tools = [get_albums_by_artist, get_tracks_by_artist, get_songs_by_genre, check_for_songs]\n",
    "\n",
    "# Bind the music tools to the language model for use in the ReAct agent\n",
    "llm_with_music_tools = llm.bind_tools(music_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Create a tool node that executes the music-related tools\n",
    "# ToolNode is a pre-built LangGraph component that handles tool execution\n",
    "music_tool_node = ToolNode(music_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage, SystemMessage, HumanMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "def generate_music_assistant_prompt(memory: str = \"None\") -> str:\n",
    "    \"\"\"\n",
    "    Generate a system prompt for the music assistant agent.\n",
    "    \n",
    "    Args:\n",
    "        memory (str): User preferences and context from long-term memory store\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted system prompt for the music assistant\n",
    "    \"\"\"\n",
    "    return f\"\"\"\n",
    "    You are a member of the assistant team, your role specifically is to focused on helping customers discover and learn about music in our digital catalog. \n",
    "    If you are unable to find playlists, songs, or albums associated with an artist, it is okay. \n",
    "    Just inform the customer that the catalog does not have any playlists, songs, or albums associated with that artist.\n",
    "    You also have context on any saved user preferences, helping you to tailor your response. \n",
    "    \n",
    "    CORE RESPONSIBILITIES:\n",
    "    - Search and provide accurate information about songs, albums, artists, and playlists\n",
    "    - Offer relevant recommendations based on customer interests\n",
    "    - Handle music-related queries with attention to detail\n",
    "    - Help customers discover new music they might enjoy\n",
    "    - You are routed only when there are questions related to music catalog; ignore other questions. \n",
    "    \n",
    "    SEARCH GUIDELINES:\n",
    "    1. Always perform thorough searches before concluding something is unavailable\n",
    "    2. If exact matches aren't found, try:\n",
    "       - Checking for alternative spellings\n",
    "       - Looking for similar artist names\n",
    "       - Searching by partial matches\n",
    "       - Checking different versions/remixes\n",
    "    3. When providing song lists:\n",
    "       - Include the artist name with each song\n",
    "       - Mention the album when relevant\n",
    "       - Note if it's part of any playlists\n",
    "       - Indicate if there are multiple versions\n",
    "    \n",
    "    Additional context is provided below: \n",
    "\n",
    "    Prior saved user preferences: {memory}\n",
    "    \n",
    "    Message history is also attached.  \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def music_assistant(state: State, config: RunnableConfig):\n",
    "    \"\"\"\n",
    "    Music assistant node that handles music catalog queries and recommendations.\n",
    "    \n",
    "    This node processes customer requests related to music discovery, album searches,\n",
    "    artist information, and personalized recommendations based on stored preferences.\n",
    "    \n",
    "    Args:\n",
    "        state (State): Current state containing customer_id, messages, loaded_memory, etc.\n",
    "        config (RunnableConfig): Configuration for the runnable execution\n",
    "        \n",
    "    Returns:\n",
    "        dict: Updated state with the assistant's response message\n",
    "    \"\"\"\n",
    "    # Retrieve long-term memory preferences if available\n",
    "    memory = \"None\" \n",
    "    if \"loaded_memory\" in state: \n",
    "        memory = state[\"loaded_memory\"]\n",
    "\n",
    "    # Generate instructions for the music assistant agent\n",
    "    music_assistant_prompt = generate_music_assistant_prompt(memory)\n",
    "\n",
    "    # Invoke the language model with tools and system prompt\n",
    "    # The model can decide whether to use tools or respond directly\n",
    "    response = llm_with_music_tools.invoke([SystemMessage(music_assistant_prompt)] + state[\"messages\"])\n",
    "    \n",
    "    # Return updated state with the assistant's response\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: State, config: RunnableConfig):\n",
    "    \"\"\"\n",
    "    Conditional edge function that determines the next step in the ReAct agent workflow.\n",
    "    \n",
    "    This function examines the last message in the conversation to decide whether the agent\n",
    "    should continue with tool execution or end the conversation.\n",
    "    \n",
    "    Args:\n",
    "        state (State): Current state containing messages and other workflow data\n",
    "        config (RunnableConfig): Configuration for the runnable execution\n",
    "        \n",
    "    Returns:\n",
    "        str: Either \"continue\" to execute tools or \"end\" to finish the workflow\n",
    "    \"\"\"\n",
    "    # Get all messages from the current state\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # Examine the most recent message to check for tool calls\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # If the last message doesn't contain any tool calls, the agent is done\n",
    "    if not last_message.tool_calls:\n",
    "        return \"end\"\n",
    "    # If there are tool calls present, continue to execute them\n",
    "    else:\n",
    "        return \"continue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from utils import show_graph\n",
    "\n",
    "# Create a new StateGraph instance for the music workflow\n",
    "music_workflow = StateGraph(State)\n",
    "\n",
    "# Add nodes to the graph\n",
    "# music_assistant: The reasoning node that decides which tools to invoke or responds directly\n",
    "music_workflow.add_node(\"music_assistant\", music_assistant)\n",
    "# music_tool_node: The execution node that handles all music-related tool calls\n",
    "music_workflow.add_node(\"music_tool_node\", music_tool_node)\n",
    "\n",
    "# Add edges to define the flow of the graph\n",
    "# Set the entry point - all queries start with the music assistant\n",
    "music_workflow.add_edge(START, \"music_assistant\")\n",
    "\n",
    "# Add conditional edge from music_assistant based on whether tools need to be called\n",
    "music_workflow.add_conditional_edges(\n",
    "    \"music_assistant\",\n",
    "    # Conditional function that determines the next step\n",
    "    should_continue,\n",
    "    {\n",
    "        # If tools need to be executed, route to tool node\n",
    "        \"continue\": \"music_tool_node\",\n",
    "        # If no tools needed, end the workflow\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# After tool execution, always return to the music assistant for further processing\n",
    "music_workflow.add_edge(\"music_tool_node\", \"music_assistant\")\n",
    "\n",
    "# Compile the graph with checkpointer for short-term memory and store for long-term memory\n",
    "music_catalog_subagent = music_workflow.compile(\n",
    "    name=\"music_catalog_subagent\", \n",
    "    checkpointer=checkpointer, \n",
    "    store=in_memory_store\n",
    ")\n",
    "\n",
    "# Display the compiled graph structure\n",
    "show_graph(music_catalog_subagent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the SubAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# Generate a unique thread ID for this conversation session\n",
    "thread_id = uuid.uuid4()\n",
    "\n",
    "# Define the user's question about music recommendations\n",
    "question = \"I like the Rolling Stones. What songs do you recommend by them or by other artists that I might like?\"\n",
    "\n",
    "# Set up configuration with the thread ID for maintaining conversation context\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "# Invoke the music catalog subagent with the user's question\n",
    "# The agent will use its tools to search for Rolling Stones music and provide recommendations\n",
    "result = music_catalog_subagent.invoke({\"messages\": [HumanMessage(content=question)]}, config=config)\n",
    "\n",
    "# Display all messages from the conversation in a formatted way\n",
    "for message in result[\"messages\"]:\n",
    "   message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Sub Agent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool \n",
    "def get_invoices_by_customer_sorted_by_date(customer_id: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Look up all invoices for a customer using their ID.\n",
    "    The invoices are sorted in descending order by invoice date, which helps when the customer wants to view their most recent/oldest invoice, or if \n",
    "    they want to view invoices within a specific date range.\n",
    "    \n",
    "    Args:\n",
    "        customer_id (str): customer_id, which serves as the identifier.\n",
    "    \n",
    "    Returns:\n",
    "        list[dict]: A list of invoices for the customer.\n",
    "    \"\"\"\n",
    "    return db.run(f\"SELECT * FROM Invoice WHERE CustomerId = {customer_id} ORDER BY InvoiceDate DESC;\")\n",
    "\n",
    "\n",
    "@tool \n",
    "def get_invoices_sorted_by_unit_price(customer_id: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Use this tool when the customer wants to know the details of one of their invoices based on the unit price/cost of the invoice.\n",
    "    This tool looks up all invoices for a customer, and sorts the unit price from highest to lowest. In order to find the invoice associated with the customer, \n",
    "    we need to know the customer ID.\n",
    "    \n",
    "    Args:\n",
    "        customer_id (str): customer_id, which serves as the identifier.\n",
    "    \n",
    "    Returns:\n",
    "        list[dict]: A list of invoices sorted by unit price.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "        SELECT Invoice.*, InvoiceLine.UnitPrice\n",
    "        FROM Invoice\n",
    "        JOIN InvoiceLine ON Invoice.InvoiceId = InvoiceLine.InvoiceId\n",
    "        WHERE Invoice.CustomerId = {customer_id}\n",
    "        ORDER BY InvoiceLine.UnitPrice DESC;\n",
    "    \"\"\"\n",
    "    return db.run(query)\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_employee_by_invoice_and_customer(invoice_id: str, customer_id: str) -> dict:\n",
    "    \"\"\"\n",
    "    This tool will take in an invoice ID and a customer ID and return the employee information associated with the invoice.\n",
    "\n",
    "    Args:\n",
    "        invoice_id (int): The ID of the specific invoice.\n",
    "        customer_id (str): customer_id, which serves as the identifier.\n",
    "\n",
    "    Returns:\n",
    "        dict: Information about the employee associated with the invoice.\n",
    "    \"\"\"\n",
    "\n",
    "    query = f\"\"\"\n",
    "        SELECT Employee.FirstName, Employee.Title, Employee.Email\n",
    "        FROM Employee\n",
    "        JOIN Customer ON Customer.SupportRepId = Employee.EmployeeId\n",
    "        JOIN Invoice ON Invoice.CustomerId = Customer.CustomerId\n",
    "        WHERE Invoice.InvoiceId = ({invoice_id}) AND Invoice.CustomerId = ({customer_id});\n",
    "    \"\"\"\n",
    "    \n",
    "    employee_info = db.run(query, include_columns=True)\n",
    "    \n",
    "    if not employee_info:\n",
    "        return f\"No employee found for invoice ID {invoice_id} and customer identifier {customer_id}.\"\n",
    "    return employee_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all invoice-related tools for the agent\n",
    "invoice_tools = [get_invoices_by_customer_sorted_by_date, get_invoices_sorted_by_unit_price, get_employee_by_invoice_and_customer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoice_subagent_prompt = \"\"\"\n",
    "    You are a subagent among a team of assistants. You are specialized for retrieving and processing invoice information. You are routed for invoice-related portion of the questions, so only respond to them.. \n",
    "\n",
    "    You have access to three tools. These tools enable you to retrieve and process invoice information from the database. Here are the tools:\n",
    "    - get_invoices_by_customer_sorted_by_date: This tool retrieves all invoices for a customer, sorted by invoice date.\n",
    "    - get_invoices_sorted_by_unit_price: This tool retrieves all invoices for a customer, sorted by unit price.\n",
    "    - get_employee_by_invoice_and_customer: This tool retrieves the employee information associated with an invoice and a customer.\n",
    "    \n",
    "    If you are unable to retrieve the invoice information, inform the customer you are unable to retrieve the information, and ask if they would like to search for something else.\n",
    "    \n",
    "    CORE RESPONSIBILITIES:\n",
    "    - Retrieve and process invoice information from the database\n",
    "    - Provide detailed information about invoices, including customer details, invoice dates, total amounts, employees associated with the invoice, etc. when the customer asks for it.\n",
    "    - Always maintain a professional, friendly, and patient demeanor\n",
    "    \n",
    "    You may have additional context that you should use to help answer the customer's query. It will be provided to you below:\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Create the invoice information subagent using LangGraph's pre-built ReAct agent\n",
    "# This agent specializes in handling customer invoice queries and billing information\n",
    "invoice_information_subagent = create_react_agent(\n",
    "    llm,                           # Language model for reasoning and responses\n",
    "    tools=invoice_tools,           # Invoice-specific tools for database queries\n",
    "    name=\"invoice_information_subagent\",  # Unique identifier for the agent\n",
    "    prompt=invoice_subagent_prompt,       # System instructions for invoice handling\n",
    "    state_schema=State,            # State schema for data flow between nodes\n",
    "    checkpointer=checkpointer,     # Short-term memory for conversation context\n",
    "    store=in_memory_store         # Long-term memory store for persistent data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the second sub agent\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a unique thread ID for this conversation session\n",
    "thread_id = uuid.uuid4()\n",
    "\n",
    "# Define the user's question about their recent invoice and employee assistance\n",
    "question = \"My customer id is 1. What was my most recent invoice, and who was the employee that helped me with it?\"\n",
    "\n",
    "# Set up configuration with the thread ID for maintaining conversation context\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "# Invoke the invoice information subagent with the user's question\n",
    "# The agent will use its tools to search for invoice information and employee details\n",
    "result = invoice_information_subagent.invoke({\"messages\": [HumanMessage(content=question)]}, config=config)\n",
    "\n",
    "# Display all messages from the conversation in a formatted way\n",
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervisor_prompt = \"\"\"You are an expert customer support assistant for a digital music store. \n",
    "You are dedicated to providing exceptional service and ensuring customer queries are answered thoroughly. \n",
    "You have a team of subagents that you can use to help answer queries from customers. \n",
    "Your primary role is to serve as a supervisor/planner for this multi-agent team that helps answer queries from customers. \n",
    "\n",
    "Your team is composed of two subagents that you can use to help answer the customer's request:\n",
    "1. music_catalog_information_subagent: this subagent has access to user's saved music preferences. It can also retrieve information about the digital music store's music \n",
    "catalog (albums, tracks, songs, etc.) from the database. \n",
    "3. invoice_information_subagent: this subagent is able to retrieve information about a customer's past purchases or invoices \n",
    "from the database. \n",
    "\n",
    "Based on the existing steps that have been taken in the messages, your role is to generate the next subagent that needs to be called. \n",
    "This could be one step in an inquiry that needs multiple sub-agent calls. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_supervisor import create_supervisor\n",
    "\n",
    "# Create supervisor workflow using LangGraph's pre-built supervisor\n",
    "# The supervisor coordinates between multiple subagents based on the incoming queries\n",
    "supervisor_prebuilt_workflow = create_supervisor(\n",
    "    agents=[invoice_information_subagent, music_catalog_subagent],  # List of subagents to supervise\n",
    "    output_mode=\"last_message\",  # Return only the final response (alternative: \"full_history\")\n",
    "    model=llm,  # Language model for supervisor reasoning and routing decisions\n",
    "    prompt=(supervisor_prompt),  # System instructions for the supervisor agent\n",
    "    state_schema=State  # State schema defining data flow structure\n",
    ")\n",
    "\n",
    "# Compile the supervisor workflow with memory components\n",
    "# - checkpointer: Enables short-term memory within conversation threads\n",
    "# - store: Provides long-term memory storage across conversations\n",
    "supervisor_prebuilt = supervisor_prebuilt_workflow.compile(\n",
    "    name=\"music_catalog_subagent\", \n",
    "    checkpointer=checkpointer, \n",
    "    store=in_memory_store\n",
    ")\n",
    "\n",
    "# Display the compiled supervisor graph structure\n",
    "show_graph(supervisor_prebuilt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing The Multi-Agent System\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a unique thread ID for this conversation session\n",
    "thread_id = uuid.uuid4()\n",
    "\n",
    "# Define a question that tests both invoice and music catalog capabilities\n",
    "question = \"My customer ID is 1. How much was my most recent purchase? What albums do you have by U2?\"\n",
    "\n",
    "# Set up configuration with the thread ID for maintaining conversation context\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "# Invoke the supervisor workflow with the multi-part question\n",
    "# The supervisor will route to appropriate subagents for invoice and music queries\n",
    "result = supervisor_prebuilt.invoke({\"messages\": [HumanMessage(content=question)]}, config=config)\n",
    "\n",
    "# Display all messages from the conversation in a formatted way\n",
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
